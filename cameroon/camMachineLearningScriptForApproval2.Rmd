---
title: "Cameroon: Machine Learning Script for the Predition of the Approval of Paul Biya's Job Performance"
author: "Adrien Ratsimbaharison"
date: "June 23, 2019"
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

In this machine learning implementation, we follow the guidelines suggested by different data scientists who specialize in the use r statistical and programming language and particularly the Caret package, created and maintained by Max Kuhn. Among these guidelines, we found particularly useful Saurav Kaushik's "Practical guide to implement machine learning with CARET in R" and Brett Lanz's "Machine Learning with R." After the initial step of installing the Caret package and loading the dataset into r, this machine learning implementation includes the following:

* defining the problem,
* preprocessing the data if necessary,
* spliting the data into train and test sets,
* feature selection using the "recursive feature elimination"" or "rfe"" function,
* traning the models on the train set,
* generating variable importance,
* making predictions on the test set and assessing the accuracy of the predictions.


## 1. Getting started with loading the package, looking at the data, and defining the problem

Installing and loading the Caret package and its dependencies:

```{r message=FALSE, warning=FALSE, include=FALSE}
# Intalling the caret package if it is not already installed

# install.packages("caret", dependencies = c("Depends", "Suggests"))

# loading the caret package and other required packages:
library(caret)
library(dplyr)
library(haven)
library(magrittr)
library(gbm)

```

Reading the data in R and looking at its structure:

```{r Loading the data, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# Reading the data
approvalData <- read_sav("cam_r7_data_eng.sav")
approvalData <- as_tibble(approvalData)

# Looking at its structure
# str(approvalData)

# Selecting the variables of interest

approvalData <- select(approvalData, URBRUR, REGION, EA_SVC_A, EA_SVC_B, EA_SVC_C, EA_SVC_D, EA_FAC_A, EA_FAC_B, EA_FAC_C, EA_FAC_D, EA_FAC_E, EA_FAC_F, EA_FAC_G, EA_SEC_A, EA_SEC_B, EA_SEC_C, EA_SEC_D, EA_SEC_E, EA_ROAD_A, EA_ROAD_B, EA_ROAD_C, Q1, Q2A, Q2AOTHER, Q2B, Q2BOTHER, Q3, Q4A, Q4B, Q5, Q6, Q7, Q8A, Q8B, Q8C, Q8D, Q8E, Q8F, Q9, Q10A, Q10B, Q11A, Q11B, Q12A, Q12B, Q12C, Q12D, Q12E, Q13, Q14, Q15, Q16, Q17, Q18A, Q18B, Q18C, Q18D, Q19A, Q19B, Q19C, Q19D, Q19E, Q20A, Q20B, Q21A, Q21B, Q22, Q23, Q24A, Q24B, Q25A, Q25B, Q25C, Q25D, Q25E, Q25F, Q26A, Q26B, Q26C, Q26D, Q26E, Q27A, Q27B, Q27C, Q28, Q29, Q30, Q31, Q32, Q33, Q34, Q35, Q36, Q37, Q38A, Q38B, Q38C, Q38D, Q38E, Q38F, Q38G, Q39A, Q39B, Q39C, Q40, Q41, Q42A, Q42B, Q42C, Q42D, Q42E, Q42F, Q43A, Q43B, Q43C, Q43D, Q43E, Q43F, Q43G, Q43H, Q43I, Q43J, Q43K, Q43L_CAM, Q43M_CAM, Q44A, Q44B, Q44C, Q44D, Q44E, Q44F, Q44G, Q44H, Q44I, Q44J, Q44K_CAM, Q44L_CAM, Q44M_CAM, Q44N_CAM, Q45, Q46, Q47, Q48A, Q48B, Q48C, Q48D, Q48E, Q48F, Q49A, Q49B, Q49C, Q49D, Q49E, Q49F, Q49G, Q49H, Q49I, Q49J, Q49K, Q49L, Q49M, Q49N, Q49O, Q49P, Q49Q, Q49R, Q49S, Q49T, Q50, Q51, Q52, Q53A, Q53B, Q53C, Q54A, Q54B, Q55PT1, Q55PT1OTHER, Q55PT2, Q55PT2OTHER, Q55PT3, Q55PT3OTHER, Q56A, Q56B, Q56C, Q56D, Q56E, Q56F, Q56G, Q56H, Q56I, Q56J, Q56K, Q56L, Q56M, Q56N, Q56O, Q56P, Q56Q, Q56R, Q56S, Q57A, Q57B, Q57C, Q57D, Q57E, Q57F, Q57G, Q58A, Q58B, Q58C, Q58D, Q58E, Q59A, Q59B, Q59C, Q60A, Q60B, Q60C, Q60D, Q61A, Q61B, Q61C, Q62, Q63, Q64, Q65, Q66, Q67, Q68A, Q68B, Q69, Q70, Q70OTHER, Q71, Q72A, Q72B, Q73A, Q73B, Q74, Q75, Q76, Q77A, Q77B, Q77C, Q77D, Q78A, Q78B, Q79_CAM, Q80_CAM, Q81A_CAM, Q81B_CAM, Q81C_CAM, Q81D_CAM, Q82A_CAM, Q82B_CAM, Q82C_CAM, Q82D_CAM, Q84, Q84OTHER, Q85A, Q85B, Q86A, Q86B, Q86C, Q86D, Q87A, Q87B, Q87C, Q87D, Q88A,Q88B, Q88BOTHER, Q89A, Q89B, Q89C, Q89D, Q89E, Q89F, Q90, Q91A, Q91B, Q92A, Q92B, Q93, Q94, Q95A, Q95B, Q95C, Q96A, Q96B, Q97, Q98, Q98OTHER, Q99, Q99OTHER, Q100)

# Changing the types of all variables to factor, except the variable "age" which should be kept numeric
approvalData %<>% 
      mutate_each(funs(if(is.numeric(.)) as.factor(.) else .))

approvalData$Q1 <- as.numeric(approvalData$Q1)

# we need also to remove the variables that end with "OTHER" which created the errors "NA/NaN/Inf in foreign function call (arg 1)" in the execution of feature selection using the "rfe" function in step 4;

approvalData <- select(approvalData, - c(Q2AOTHER, Q2BOTHER, Q55PT3OTHER, Q55PT2OTHER, Q55PT1OTHER, Q70OTHER, Q98OTHER, Q84OTHER, Q88BOTHER, Q99OTHER))

```


Defining the problem:

The problem in this machine learning is to predict the "approval" of Paul Biya's job performance (i.e, the responses to the mutated variable Q58A of the Cameroon Round 7 survey ("Do you approve or disapprove of the way that the President has performed his jobs over the past 12 months?”). In other words, we are dealing here with a machine learning classification into three categories:


* "disapproval" (for those who simply "disapprove" or "strongly dispprove" the way the President has performed his job),
* "approval" (for those who simply "approve" or "strongly approve" the way the President has performed his job)
* "don't know" (for those who refuse to answer the question or don’t know whether to approve or not the way the President has performed his job)

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

# In order to simplify the interpretation of the results of the machine learning implementation, we need to create the variable "approval" with three categories of responses, by mutating Q58A and assigning the following value: 0 = "Disapproval", 1 = "Approval", 2 = "Don't know"
approvalData <- mutate(approvalData, approval = ifelse(Q58A == 1 | Q58A == 2, "0",
                                           ifelse(Q58A == 3 | Q58A == 4, "1", "2" )))

approvalData$approval <- as.factor(approvalData$approval)


# we remove Q5BA from the dataset, as it is redundant with the new variable approval
approvalData <- select(approvalData, - Q58A)
approvalData_transformed <- approvalData

```


## 2. Pre-processing the data using Caret

In this step, we only check for the missing values, and skipped the other pre-processing procedures, such as centering, scaling, principal component analysis, and creation of "one hot encoding". 

```{r cheking NA, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

sum(is.na(approvalData_transformed))

```

Since there is no missing value to remove, we can move to the next step, which is splitting the data.



## 3. Splitting the data using Caret

Since the dataset was initially arranged in a country-year format, it is a good idea to randomize the rows before splitting the dataset into trainSet and testSet. 

```{r randomization and splitting of the data, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# Randomizing the dataset
set.seed(123)
rows <- sample(nrow(approvalData_transformed))
approvalData_transformed <- approvalData_transformed[rows,]

#Spliting dataset into trainSet and testSet based on outcome with a ratio of 75% and 25%, using createDataPartition in Caret
set.seed(234)
index <- createDataPartition(approvalData_transformed$approval, p=0.75, list=FALSE)
approvalTrainSet <- approvalData_transformed[index,]
approvalTestSet <- approvalData_transformed[-index,]

#Checking the structure of approvalTrainSet
str(approvalTrainSet)

```



## 4. Feature selection using Caret

The feature selection, which is suggested by most data scientists, is made easy by Caret. The "recursive feature elimination" or "rfe" function in Caret is used to find the best subset of features to be included in the models.

```{r Feature selection using rfe, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# Feature selection using rfe in caret
ctrl <- rfeControl(functions = rfFuncs,
                   method = "repeatedcv",
                   repeats = 3,
                   verbose = FALSE)

y <- approvalTrainSet$approval
x <- select(approvalTrainSet, - approval)

approvalProfile <- rfe(x, y,
                rfeControl = ctrl)

approvalProfile

```



## 5. Training models using Caret

Caret provides a large number of algorithms with similar syntax. After trying different models, we decide to use Gradient Boosting Machines (GBM) and Random Forest (RF). Nevertheless, since the GBM model generates the highest prediction accuracy of these two models, we focus on the results from this model in this study.

```{r Trianing the models, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
fitControl <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 3)
approvalModel_gbm <- train(approval ~ ., data = approvalTrainSet, 
                 method = "gbm", 
                 trControl = fitControl,
                 verbose = FALSE)

approvalModel_rf <- train(approval ~ ., data = approvalTrainSet, 
                 method = "rf", 
                 trControl = fitControl,
                 verbose = FALSE,
                 importance=T)


```


## 6. Variable importance estimation using Caret

We can also check the variable importance estimates in Caret by using the "varImp" function" for any model.

### 6.1 Variable importance with GBM

```{r Variable importance with GBM, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
# Checking variable importance with GBM
# Variable Importance
varImp(object=approvalModel_gbm)


#Plotting Variable importance for GBM model
plot(varImp(object=approvalModel_gbm),main="Variable Importance Using GBM", top = 20)

```

### 6.2 Variable importance with RF

```{r Variable importance with RF, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
#Checking variable importance for RF
varImp(object=approvalModel_rf)
#rf variable importance


#Plotting Varianle importance for Random Forest
plot(varImp(object=approvalModel_rf),main="RF - Variable Importance", top = 20)

```


## 7. Making predictions using Caret

```{r}
#Predictions with gbm
approvalPrediction_gbm <-predict.train(object=approvalModel_gbm,approvalTestSet,type="raw")
table(approvalPrediction_gbm)

confusionMatrix(approvalPrediction_gbm,approvalTestSet$approval)


```



```{r}
#Predictions with rf
approvalPrediction_rf <-predict.train(object=approvalModel_rf,approvalTestSet,type="raw")
table(approvalPrediction_rf)

confusionMatrix(approvalPrediction_rf,approvalTestSet$approval)

```


## Conclusion

The predictors identified in this machine learning are the following variables:

- Q43A(1 to 9): "How much do you trust *the President*, or haven’t you heard enough about *him* to say?"
- Q58B(1 to 9): "Do you approve or disapprove of the way that *your member of Parliament* has performed *her/his* jobs over the past 12 months?”
- REGION: Regional location of the respondent
- Q36(1 to 9): "Overall, how satisfied are you with the way democracy works in Cameroon?"
- Q32(1 to 9): "Do you agree with the following statements? Statement 1: Parliament should ensure that the president explains to it on a regular basis how his government spends taxpayers’ money. Statement 2: The president should be able to devote his full attention to developing the country rather than wasting time justifying his actions."
- Q43G3: "How much do you trust *the police*, or haven’t you heard enough about *him* to say? "
- Q99(1220 to 9999): "If presidential elections were held tomorrow, which party’s candidate would you vote for?"
- Q58D(1 to 9): "Do you approve or disapprove of the way that *your traditional leader* has performed *her/his* jobs over the past 12 months?”
- Q44A(1 to 9): "How [often] do you think [the president was] involved in corruption, or haven’t you heard enough about them to say?"
- Q44K_CAM(1 to 9): "How [often] do you think [the customs officers were] involved in corruption, or haven’t you heard enough about them to say?"
- Q26E(1 to 9): "whether you, personally, have [participated in a demonstration or protest march] during the past year"
- Q24B(0 to 9): "Did you work for a candidate or party [during the last national election in 2013]?"
- Q1: "How old are you?"
- Q42E(1 to 9): "In your opinion, how often, in this country, do officials who commit crimes go unpunished?"
